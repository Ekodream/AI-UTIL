import pyautogui
import cv2
import numpy as np
import time
import os
import base64
from PIL import Image
from openai import OpenAI

# ============================================
# ä¸€ã€æˆªå›¾ä¸ç¿»é¡µéƒ¨åˆ†
# ============================================
SAVE_DIR = "image"                     # æˆªå›¾ä¿å­˜æ–‡ä»¶å¤¹
os.makedirs(SAVE_DIR, exist_ok=True)

BUTTON_IMAGE = "next_button.png"       # ç¿»é¡µæŒ‰é’®æˆªå›¾æ–‡ä»¶
CONFIDENCE = 0.8                       # æŒ‰é’®è¯†åˆ«ç›¸ä¼¼åº¦
SCREEN_REGION = None                   # æˆªå±èŒƒå›´ï¼ˆNone = å…¨å±ï¼‰
SIMILARITY_THRESHOLD = 0.99            # åˆ¤æ–­æˆªå›¾ç›¸ä¼¼åº¦ï¼ˆç”¨äºæ£€æµ‹åˆ°åº•ï¼‰

def take_screenshot(filename):
    """æˆªå±ä¿å­˜"""
    screenshot = pyautogui.screenshot(region=SCREEN_REGION)
    screenshot.save(filename)
    print(f"[+] æˆªå›¾å·²ä¿å­˜ï¼š{filename}")

def images_are_same(img1_path, img2_path, threshold=SIMILARITY_THRESHOLD):
    """åˆ¤æ–­ä¸¤å¼ æˆªå›¾æ˜¯å¦ç›¸åŒ"""
    img1 = cv2.imread(img1_path)
    img2 = cv2.imread(img2_path)
    if img1 is None or img2 is None or img1.shape != img2.shape:
        return False
    diff = cv2.absdiff(img1, img2)
    non_zero_count = np.count_nonzero(diff)
    total_pixels = diff.size / 3
    similarity = 1 - non_zero_count / total_pixels
    return similarity > threshold

def find_and_click_next():
    """è‡ªåŠ¨æŸ¥æ‰¾å¹¶ç‚¹å‡»"ä¸‹ä¸€é¡µ"æŒ‰é’®"""
    max_attempts = 5
    attempt = 0
    while attempt < max_attempts:
        button_location = pyautogui.locateOnScreen(BUTTON_IMAGE, confidence=CONFIDENCE)
        if button_location is not None:
            x, y = pyautogui.center(button_location)
            pyautogui.click(x, y)
            print(f"[â†’] ç‚¹å‡»ç¿»é¡µæŒ‰é’®ï¼Œåæ ‡ï¼š({x}, {y})")
            time.sleep(2)  # ç­‰å¾…é¡µé¢åŠ è½½
            pyautogui.moveTo(100, 200)
            pyautogui.click()
            return True
        else:
            attempt += 1
            print("æœªæ‰¾åˆ°ç¿»é¡µæŒ‰é’®ï¼Œé‡è¯•...")
            time.sleep(1)
    print("âš ï¸ ç¿»é¡µæŒ‰é’®æ‰¾ä¸åˆ°ï¼Œå¯èƒ½å·²åˆ°åº•ã€‚")
    return False

def capture_all_pages():
    """è‡ªåŠ¨æˆªå±å¹¶ä¿å­˜åˆ° image/ æ–‡ä»¶å¤¹"""
    print("å¼€å§‹è‡ªåŠ¨æˆªå± + è‡ªåŠ¨ç¿»é¡µæµç¨‹...")
    index = 0
    prev_img = os.path.join(SAVE_DIR, f"page_{index}.png")
    take_screenshot(prev_img)

    while True:
        if not find_and_click_next():
            break
        index += 1
        curr_img = os.path.join(SAVE_DIR, f"page_{index}.png")
        take_screenshot(curr_img)

        if images_are_same(prev_img, curr_img):
            print("æ£€æµ‹åˆ°ä¸¤å¼ æˆªå›¾ç›¸åŒï¼Œå·²åˆ°åº•ã€‚ç¨‹åºç»“æŸã€‚")
            os.remove(curr_img)
            break
        else:
            prev_img = curr_img

    print(f"âœ… æˆªå›¾å®Œæˆï¼Œå…± {index+1} é¡µã€‚")


# ============================================
# äºŒã€AIå›¾ç‰‡åˆ†æéƒ¨åˆ†
# ============================================
def analyze_images_with_ai(custom_prompt=None):
    """ä» image/ æ–‡ä»¶å¤¹è¯»å–æ‰€æœ‰å›¾ç‰‡å¹¶ä¸€æ¬¡æ€§å‘ç»™ AI åˆ†æï¼Œç”ŸæˆHTMLè¡¨æ ¼"""
    # åˆ›å»ºhtmlè¾“å‡ºç›®å½•
    html_dir = "html"
    os.makedirs(html_dir, exist_ok=True)
    
    # ä»ç¯å¢ƒå˜é‡è·å–API Key
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        print("âŒ æœªæ‰¾åˆ°ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEYï¼Œè¯·è®¾ç½®åé‡è¯•ã€‚")
        print("ğŸ’¡ è®¾ç½®æ–¹æ³•ï¼šåœ¨ç³»ç»Ÿç¯å¢ƒå˜é‡ä¸­æ·»åŠ  DASHSCOPE_API_KEY=ä½ çš„APIå¯†é’¥")
        return
    
    client = OpenAI(
        api_key=api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )

    image_files = sorted([f for f in os.listdir(SAVE_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
    if not image_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡ï¼Œè¯·å…ˆè¿è¡Œæˆªå›¾éƒ¨åˆ†ã€‚")
        return

    print(f"ğŸ“¸ æ£€æµ‹åˆ° {len(image_files)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹æ‰¹é‡åˆ†æ...\n")

    # æ„å»ºæ¶ˆæ¯å†…å®¹ï¼ŒåŒ…å«æ‰€æœ‰å›¾ç‰‡
    content_list = []
    
    # æ·»åŠ æ‰€æœ‰å›¾ç‰‡
    for i, img_name in enumerate(image_files):
        img_path = os.path.join(SAVE_DIR, img_name)
        with open(img_path, "rb") as f:
            img_base64 = base64.b64encode(f.read()).decode("utf-8")
        
        content_list.append({
            "type": "image_url",
            "image_url": {"url": "data:image/png;base64," + img_base64}
        })
        print(f"ğŸ“· å·²åŠ è½½ç¬¬ {i+1} å¼ å›¾ç‰‡ï¼š{img_name}")

    prompt_text = f"""è¿™æ˜¯2025å¹´ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦æ´»åŠ¨å‘å¸ƒå¹³å°çš„ç•Œé¢ï¼Œå…±{len(image_files)}å¼ å›¾ç‰‡ã€‚
        è¯·æ ¹æ®è¦æ±‚åˆ†æå›¾ç‰‡ä¸­çš„æ´»åŠ¨ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„HTMLé¡µé¢ï¼Œå†…å®¹ä¸ºè¡¨æ ¼å½¢å¼ã€‚

        åŸºæœ¬è¦æ±‚ï¼š
        1. ç”Ÿæˆå®Œæ•´çš„HTMLæ–‡æ¡£ç»“æ„ï¼ˆåŒ…å«<!DOCTYPE html>, <html>, <head>, <body>ç­‰æ ‡ç­¾ï¼‰
        2. é™¤äº†è¡¨æ ¼å¤–æ— å…¶ä»–å†…å®¹
        3. åœ¨<head>ä¸­æ·»åŠ åˆé€‚çš„CSSæ ·å¼ï¼Œè®©è¡¨æ ¼ç¾è§‚ï¼ˆè¾¹æ¡†ã€é¢œè‰²ã€å­—ä½“ç­‰ï¼‰
        4. è¡¨æ ¼åˆ—åŒ…å«ï¼šè§’æ ‡ | æ´»åŠ¨åç§° | ç»„ç»‡æ–¹ | æŠ¥åæˆªæ­¢æ—¶é—´
        5. è¯†åˆ«æ¯ä¸ªæ´»åŠ¨æ—çš„"å¾·""æ™º""ä½“""ç¾""åŠ³"äº”ç§è§’æ ‡å¹¶åœ¨è¡¨æ ¼ä¸­ä½“ç°
        """

    # æ·»åŠ æ–‡æœ¬æç¤ºï¼ˆæ”¯æŒè‡ªå®šä¹‰promptï¼‰
    if custom_prompt:
        prompt_text = prompt_text + "\n\n" \
            + "è‡ªå®šä¹‰è¦æ±‚ï¼š" + custom_prompt \
            + "\nè¯·ç»“åˆåŸºæœ¬è¦æ±‚å’Œè‡ªå®šä¹‰è¦æ±‚ç”Ÿæˆç›¸åº”çš„HTMLä»£ç ã€‚"
        print(f"ğŸ”§ ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯...")
    
    content_list.append({
        "type": "text",
        "text": prompt_text
    })

    print(f"ğŸ§  æ­£åœ¨ä¸€æ¬¡æ€§åˆ†æ {len(image_files)} å¼ å›¾ç‰‡...")
    
    completion = client.chat.completions.create(
        model="qwen3-vl-flash",
        messages=[
            {
                "role": "user",
                "content": content_list
            }
        ],
        stream=False,
        extra_body={
            "enable_thinking": False,
            "thinking_budget": 81920
        },
    )

    print("=" * 50 + " ç”ŸæˆHTMLæ–‡ä»¶ " + "=" * 50)

    # å…¼å®¹ Qwen è¿”å›æ ¼å¼ï¼ˆå¯èƒ½æ˜¯ str æˆ– listï¼‰
    content = completion.choices[0].message.content
    html_content = ""
    
    if isinstance(content, str):
        html_content = content
    elif isinstance(content, list):
        for part in content:
            if isinstance(part, dict) and part.get("text"):
                html_content += part["text"]
    
    if html_content:
        # ç”ŸæˆHTMLæ–‡ä»¶åï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        html_filename = os.path.join(html_dir, f"activities_{timestamp}.html")
        
        # ä¿å­˜HTMLæ–‡ä»¶
        with open(html_filename, "w", encoding="utf-8") as f:
            f.write(html_content)
        
        print(f"âœ… HTMLæ–‡ä»¶å·²ç”Ÿæˆï¼š{html_filename}")
        print(f"ğŸ“– è¯·ç”¨æµè§ˆå™¨æ‰“å¼€æŸ¥çœ‹æ´»åŠ¨æ±‡æ€»è¡¨æ ¼")
    else:
        print("âŒ AIæœªè¿”å›æœ‰æ•ˆçš„HTMLå†…å®¹")

    print("\nâœ… æ‰¹é‡å›¾ç‰‡åˆ†æå®Œæˆï¼")



# ============================================
# ä¸‰ã€ä¸»ç¨‹åºå…¥å£
# ============================================
def main():
    """ä¸»ç¨‹åºå…¥å£"""
    print("=" * 50)
    print("ğŸ“ ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦æ´»åŠ¨å‘å¸ƒå¹³å°åˆ†æå·¥å…·")
    print("=" * 50)
    
    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œï¼š")
        print("1. è‡ªåŠ¨æˆªå›¾å¹¶ç¿»é¡µ")
        print("2. ä½¿ç”¨é»˜è®¤æç¤ºè¯åˆ†æå›¾ç‰‡å¹¶ç”ŸæˆHTML")
        print("3. ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯åˆ†æå›¾ç‰‡å¹¶ç”ŸæˆHTML")
        print("4. é€€å‡ºç¨‹åº")
        
        choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1-4): ").strip()
        
        if choice == "1":
            print("ç¨‹åºå°†åœ¨ 3 ç§’åå¼€å§‹æˆªå›¾ï¼Œè¯·åˆ‡æ¢åˆ°éœ€è¦æˆªå›¾çš„çª—å£...")
            time.sleep(3)
            capture_all_pages()
        
        elif choice == "2":
            analyze_images_with_ai()
        
        elif choice == "3":
            print("\n" + "=" * 30)
            print("è‡ªå®šä¹‰æç¤ºè¯è¾“å…¥")
            print("=" * 30)
            print("ğŸ’¡ æç¤ºï¼šè¯·è¾“å…¥ä½ å¸Œæœ›AIå¦‚ä½•åˆ†æå›¾ç‰‡çš„æŒ‡ä»¤")
            print("ğŸ’¡ å»ºè®®åŒ…å«ï¼šè¾“å‡ºæ ¼å¼ã€åˆ†æé‡ç‚¹ã€ç‰¹æ®Šè¦æ±‚ç­‰")
            print("ğŸ’¡ ç•™ç©ºå¹¶æŒ‰å›è½¦å°†ä½¿ç”¨é»˜è®¤æç¤ºè¯")
            print("-" * 30)
            
            custom_prompt = input("è¯·è¾“å…¥è‡ªå®šä¹‰æç¤ºè¯: ").strip()
            
            if not custom_prompt:
                print("âš ï¸ æœªè¾“å…¥è‡ªå®šä¹‰æç¤ºè¯ï¼Œå°†ä½¿ç”¨é»˜è®¤æç¤ºè¯")
                analyze_images_with_ai()
            else:
                print(f"âœ… å·²è®¾ç½®è‡ªå®šä¹‰æç¤ºè¯ï¼ˆé•¿åº¦: {len(custom_prompt)} å­—ç¬¦ï¼‰")
                analyze_images_with_ai(custom_prompt)
        
        elif choice == "4":
            print("ğŸ‘‹ ç¨‹åºå·²é€€å‡ºï¼Œå†è§ï¼")
            break
        
        else:
            print("âŒ æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°è¾“å…¥")

if __name__ == "__main__":
    main()
